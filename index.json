[{"categories":null,"contents":"Person Tracking in Uniform appearance Group dataset. Provided by VSAP Labs\nPerson-tracking robots have many applications including security, surveillance, and autonomous driving. Despite the abundance of uniform crowds in many contexts and the challenges they exhibit, there is a lack of video datasets dedicated to benchmarking tracking algorithms in such contexts. This paper proposes a new RGB-D benchmark called PTUC, a high-quality benchmark for Person Tracking in Uniform Crowd. PTUC is recorded using an RGB-D sensor on top of a moving robot and consists of 45 sequences with more than 85K frames in total. Each frame in the sequence is manually annotated with a bounding box and attributes, making PTUC the largest and the most challenging person tracking RGB-D dataset. To the best of our knowledge, such a densely annotated and properly synchronized RGB-D tracking benchmark does not exist in the literature. The average video length of PTUC is 1,891 frames, and each sequence comprises various challenges deriving from real-life scenarios where the target person appears highly similar to background or distractors. By releasing PTUC, we expect to provide the community with a large-scale challenging RGB-D benchmark with high quality for robust evaluation of trackers on uniform-crowd scenarios for autonomous robots. We also present a rigorous experimental evaluation of the state-of-the-art trackers on the PTUC dataset with a comprehensive analysis. The findings evidence the challenges of person tracking in a uniform crowd for both target tracking and robot-person tracking, and the need to bridge the performance gap.\n","permalink":"https://test-gits.github.io/about/","tags":null,"title":"About PTUG"},{"categories":null,"contents":null,"permalink":"https://test-gits.github.io/","tags":null,"title":"PTUG Benchmark"}]